{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic survival classification problem\n",
    "- Download titanic dataset.\n",
    "- Train a 2-layer NN with 5 neurons per layer (input/output apart) for XX epochs and 64 batch size.\n",
    "- Save the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6HRX3PPd69L"
   },
   "outputs": [],
   "source": [
    "import boto3 # required in case we store the artifacts on s3\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.model_selection as ms\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_score, accuracy_score,recall_score, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get MLFlow server URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_uri = os.getenv('REGISTRY_URI')\n",
    "if not registry_uri:\n",
    "    raise Exception('REGISTRY_URI env variable should be defined on the system in order to log the generated model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load\n",
    "dataset = sns.load_dataset(\"titanic\")\n",
    "dataframe, test_dataframe = ms.train_test_split(dataset, train_size=0.7, random_state=1)\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format data\n",
    "dataframe = dataframe.astype({\"deck\": str})\n",
    "test_dataframe = test_dataframe.astype({\"deck\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "id": "rBLQXDX3e52R",
    "outputId": "9583b219-3f54-4440-b39a-465526898d7c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data processing\n",
    "for i in dataframe.index:\n",
    "    if dataframe['deck'][i] == 'nan':\n",
    "        dataframe.loc[i,'deck'] = 'Z'\n",
    "\n",
    "for i in test_dataframe.index:\n",
    "    if test_dataframe['deck'][i] == 'nan':\n",
    "        test_dataframe.loc[i,'deck'] = 'Z'\n",
    "\n",
    "train_median = dataframe['age'].median()\n",
    "for i in dataframe.index:\n",
    "    if dataframe['age'][i] != dataframe['age'][i]:\n",
    "        dataframe.loc[i,'age'] = train_median\n",
    "\n",
    "train_median = test_dataframe['age'].median()\n",
    "for i in test_dataframe.index:\n",
    "    if test_dataframe['age'][i] != test_dataframe['age'][i]:\n",
    "        test_dataframe.loc[i,'age'] = train_median\n",
    "\n",
    "X = dataframe[['sex', 'pclass', 'age', 'deck']]\n",
    "y = dataframe[['alive']]\n",
    "X_ts = test_dataframe[['sex', 'pclass', 'age', 'deck']]\n",
    "y_ts = test_dataframe[['alive']]\n",
    "X_ts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "id": "HByq3PZau4yA",
    "outputId": "a965de61-e7c8-4180-935f-9e7d741bbf55"
   },
   "outputs": [],
   "source": [
    "# normalization\n",
    "normalization = [X.loc[:, 'age'].mean(), X.loc[:, 'age'].std()]\n",
    "print(\"Age normalization --> \" + str(normalization))\n",
    "\n",
    "X.loc[:, 'age'] = (X.loc[:, 'age'] - normalization[0]) / normalization[1]\n",
    "X_ts.loc[:, 'age'] = (X_ts.loc[:, 'age'] - normalization[0]) / normalization[1]\n",
    "\n",
    "X_dum = pd.get_dummies(X)\n",
    "X_ts_dum = pd.get_dummies(X_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y0mpaCD7F2oU",
    "outputId": "9f0ff756-73d7-44f5-e426-8a499d898eb5"
   },
   "outputs": [],
   "source": [
    "# dummification\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y.values.ravel())\n",
    "y = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "integer_encoded_ts = label_encoder.fit_transform(y_ts.values.ravel())\n",
    "y_ts = integer_encoded_ts.reshape(len(integer_encoded_ts), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6__EfUNR2S33",
    "outputId": "9ecbb7eb-29fc-4569-d8ae-c3c39819949e"
   },
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.01)\n",
    "\n",
    "# model definition\n",
    "input = Input(len(X_dum.columns))\n",
    "layer_1 = Dense(5, activation='relu')(input)\n",
    "layer_2 = Dense(5, activation='relu')(layer_1)\n",
    "output = Dense(1, activation='sigmoid')(layer_2)\n",
    "\n",
    "model = Model(input, output)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "          optimizer=opt,\n",
    "          metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m_RSOAGo-JXG",
    "outputId": "eebb7f41-dba0-4754-f8e2-cb1d92026dec"
   },
   "outputs": [],
   "source": [
    "hist=model.fit(X_dum, \n",
    "               y,\n",
    "               batch_size=64,\n",
    "               epochs=5,\n",
    "               validation_split=0.1,\n",
    "               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"titanic_DeepLearn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict(X_ts_dum)\n",
    "fpr, tpr, _ = roc_curve(y_ts, probabilities)\n",
    "auc = auc(fpr, tpr)\n",
    "print(\"Max ROC:\")\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the classifier\n",
    "mlflow.set_tracking_uri(registry_uri)\n",
    "mlflow.set_experiment('NeuralNetwork')\n",
    "\n",
    "with mlflow.start_run(run_name='forest_gump'):\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "    mlflow.keras.log_model(keras_model=model, artifact_path='', registered_model_name='neural_network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.where(probabilities > .5, 1, 0)\n",
    "cm = confusion_matrix(y_true=y_ts, y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Survivor', 'Dead']\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(history):\n",
    "  plt.figure()\n",
    "  plt.xlabel('Épocas')\n",
    "  plt.ylabel('Error')\n",
    "  plt.plot(history['loss'])\n",
    "  plt.plot(history['val_loss'])\n",
    "  plt.legend(['Entrenamiento', 'Validación'])\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Épocas')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.plot(history['accuracy'])\n",
    "  plt.plot(history['val_accuracy'])\n",
    "  plt.legend(['Entrenamiento', 'Validación'], loc='lower right')\n",
    "\n",
    "plot_curves(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Te damos la bienvenida a Colaboratory",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
