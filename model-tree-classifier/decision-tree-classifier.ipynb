{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree classifier: Car safety"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code and data taken from: https://www.kaggle.com/prashant111/decision-tree-classifier-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import mlflow\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get MLFlow server URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_uri = os.getenv('REGISTRY_URI')\n",
    "if not registry_uri:\n",
    "    raise Exception('REGISTRY_URI env variable should be defined on the system in order to log the generated model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = 'car_evaluation.csv'\n",
    "df = pd.read_csv(data, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view dimensions of dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1728 instances and 7 variables in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the top of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column names\n",
    "col_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "df.columns = col_names\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the end of the dataset\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the column names are renamed. Now, the columns have meaningful names with \"**class**\" as the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in col_names:    \n",
    "    print(df[col].value_counts())\n",
    "    print (\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare feature vector and target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['class'], axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into separate training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "**Feature Engineering** is the process of transforming raw data into useful features that help us to understand our model better and increase its predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode variables with ordinal encoding\n",
    "encoder = ce.OrdinalEncoder(cols=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier with criterion gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create classifier\n",
    "md = 3\n",
    "clf_gini = DecisionTreeClassifier(criterion='gini', max_depth = md, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier and predict results\n",
    "clf_gini.fit(X_train, y_train)\n",
    "y_pred_gini = clf_gini.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# decision-tree visualization\n",
    "plt.figure(figsize=(12,8))\n",
    "tree.plot_tree(clf_gini.fit(X_train, y_train))\n",
    "plt.savefig(\"tree.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFlow code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## MLFlow snippet\n",
    "#import mlflow\n",
    "#from urllib.parse import urlparse\n",
    "#\n",
    "## with mlflow.start_run():\n",
    "#mlflow.end_run()\n",
    "#mlflow.start_run()\n",
    "#\n",
    "#tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "## Model registry does not work with file store\n",
    "#if tracking_url_type_store != \"file\":\n",
    "## Register the model\n",
    "## There are other ways to use the Model Registry, which depends on the use case,\n",
    "## please refer to the doc for more information:\n",
    "## https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "#    mlflow.sklearn.log_model(lr, \"model\", registered_model_name=\"ElasticnetWineModel\")\n",
    "#else:\n",
    "#    mlflow.sklearn.log_model(lr, \"model\")\n",
    "#\n",
    "#mlflow.end_run()\n",
    "#---------------------------------------------------------------------\n",
    "#logged_model = 'runs:/XXXXX/model'\n",
    "#loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "#\n",
    "#y_pred_gini = clf_gini.predict(X_test)\n",
    "#print('Model accuracy score with criterion gini index: {0:0.4f}'. format(accuracy_score(y_test, y_pred_gini)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## MLFlow snippet\n",
    "## locally log the classifier\n",
    "#with mlflow.start_run():\n",
    "#    mlflow.log_param(\"max_depth\", md)\n",
    "#    mlflow.log_metric(\"accuracy\", acc)\n",
    "#    mlflow.sklearn.log_model(clf_gini, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the classifier\n",
    "mlflow.set_tracking_uri(registry_uri)\n",
    "mlflow.set_experiment('TreeClassifier')\n",
    "\n",
    "with mlflow.start_run(run_name='blade_runner'):\n",
    "    mlflow.log_param(\"max_depth\", md)\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.sklearn.log_model(sk_model=clf_gini, artifact_path='', registered_model_name='tree_model')\n",
    "    mlflow.log_artifact(\"tree.jpg\", artifact_path='plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare accuracy vs. training prediction\n",
    "print('Model accuracy score with criterion gini index: {0:0.4f}'. format(acc))\n",
    "y_pred_train_gini = clf_gini.predict(X_train)\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the training-set accuracy score is 0.7865 while the test-set accuracy to be 0.8021. These two values are quite comparable. So, there is no sign of overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier with criterion entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier\n",
    "clf_en = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
    "clf_en.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_en = clf_en.predict(X_test)\n",
    "print('Model accuracy score with criterion entropy: {0:0.4f}'. format(accuracy_score(y_test, y_pred_en)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the training-set score and test-set score is same as above. The training-set accuracy score is 0.7865 while the test-set accuracy to be 0.8021. These two values are quite comparable. So, there is no sign of overfitting. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "tree.plot_tree(clf_en.fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Confusion matrix\n",
    "\n",
    "\n",
    "A confusion matrix is a tool for summarizing the performance of a classification algorithm. A confusion matrix will give us a clear picture of classification model performance and the types of errors produced by the model. It gives us a summary of correct and incorrect predictions broken down by each category. The summary is represented in a tabular form.\n",
    "\n",
    "\n",
    "Four types of outcomes are possible while evaluating a classification model performance. These four outcomes are described below:-\n",
    "\n",
    "\n",
    "**True Positives (TP)** – True Positives occur when we predict an observation belongs to a certain class and the observation actually belongs to that class.\n",
    "\n",
    "\n",
    "**True Negatives (TN)** – True Negatives occur when we predict an observation does not belong to a certain class and the observation actually does not belong to that class.\n",
    "\n",
    "\n",
    "**False Positives (FP)** – False Positives occur when we predict an observation belongs to a    certain class but the observation actually does not belong to that class. This type of error is called **Type I error.**\n",
    "\n",
    "\n",
    "\n",
    "**False Negatives (FN)** – False Negatives occur when we predict an observation does not belong to a certain class but the observation actually belongs to that class. This is a very serious error and it is called **Type II error.**\n",
    "\n",
    "\n",
    "\n",
    "These four outcomes are summarized in a confusion matrix given below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the Confusion Matrix and slice it into four pieces\n",
    "cm = confusion_matrix(y_test, y_pred_en)\n",
    "print('Confusion matrix\\n\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf_en.classes_)\n",
    "disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report\n",
    "\n",
    "**Classification report** is another way to evaluate the classification model performance. It displays the  **precision**, **recall**, **f1** and **support** scores for the model. I have described these terms in later.\n",
    "\n",
    "We can print a classification report as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "The work done in this project is inspired from following books and websites:-\n",
    "\n",
    "1. Hands on Machine Learning with Scikit-Learn and Tensorflow by Aurélién Géron\n",
    "\n",
    "2. Introduction to Machine Learning with Python by Andreas C. Müller and Sarah Guido\n",
    "\n",
    "3. https://en.wikipedia.org/wiki/Decision_tree\n",
    "\n",
    "4. https://en.wikipedia.org/wiki/Information_gain_in_decision_trees\n",
    "\n",
    "5. https://en.wikipedia.org/wiki/Entropy_(information_theory)\n",
    "\n",
    "6. https://www.datacamp.com/community/tutorials/decision-tree-classification-python\n",
    "\n",
    "7. https://stackabuse.com/decision-trees-in-python-with-scikit-learn/\n",
    "\n",
    "8. https://acadgild.com/blog/decision-tree-python-code\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
